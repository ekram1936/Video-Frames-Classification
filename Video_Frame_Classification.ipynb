{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Video_Frame_Classification.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.1"
    },
    "varInspector": {
      "cols": {
        "lenName": 16,
        "lenType": 16,
        "lenVar": 40
      },
      "kernels_config": {
        "python": {
          "delete_cmd_postfix": "",
          "delete_cmd_prefix": "del ",
          "library": "var_list.py",
          "varRefreshCmd": "print(var_dic_list())"
        },
        "r": {
          "delete_cmd_postfix": ") ",
          "delete_cmd_prefix": "rm(",
          "library": "var_list.r",
          "varRefreshCmd": "cat(var_dic_list()) "
        }
      },
      "types_to_exclude": [
        "module",
        "function",
        "builtin_function_or_method",
        "instance",
        "_Feature"
      ],
      "window_display": false
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sv8cZGbhgoK-"
      },
      "source": [
        "%matplotlib inline\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import random\n",
        "import zipfile as zf\n",
        "import cv2\n",
        "import tensorflow as tf\n",
        "import pickle\n",
        " \n",
        "from sklearn.metrics import classification_report,confusion_matrix\n",
        "from sklearn import metrics\n",
        "from sklearn.preprocessing import LabelBinarizer,LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        " \n",
        "from keras.models import Sequential,Model\n",
        "from keras.layers import Conv2D,Dense,Flatten,Dropout,AveragePooling2D,MaxPool2D,Input\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "from keras.optimizers import Adam,RMSprop,SGD,Nadam,Adamax,Adadelta,Adagrad\n",
        "from keras.applications import ResNet50\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.utils import np_utils\n",
        " \n",
        "from imutils import build_montages\n",
        " \n",
        "sns.set()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TJwToPHscdkX"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CY1NkjWup8SM"
      },
      "source": [
        "os.getcwd()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-aUg6Q2fpaZN"
      },
      "source": [
        "\n",
        "# Read the video of basket from specified path \n",
        "cam1 = cv2.VideoCapture(\"thesis_data/christian/1.mp4\")\n",
        "cam2 = cv2.VideoCapture(\"thesis_data/christian/2.mp4\")\n",
        "cam3 = cv2.VideoCapture(\"thesis_data/christian/3.mp4\")\n",
        "cam4 = cv2.VideoCapture(\"thesis_data/christian/4.mp4\")\n",
        "cam5 = cv2.VideoCapture(\"thesis_data/christian/5.mp4\")\n",
        "cam6 = cv2.VideoCapture(\"thesis_data/christian/6.mp4\")\n",
        "cam7 = cv2.VideoCapture(\"thesis_data/christian/7.mp4\")\n",
        "cam8 = cv2.VideoCapture(\"thesis_data/christian/8.mp4\")\n",
        "cam9 = cv2.VideoCapture(\"thesis_data/christian/9.mp4\")\n",
        "cam10 = cv2.VideoCapture(\"thesis_data/christian/10.mp4\")\n",
        "cam11 = cv2.VideoCapture(\"thesis_data/christian/11.mp4\")\n",
        "cam12 = cv2.VideoCapture(\"thesis_data/christian/12.mp4\")\n",
        "\n",
        "cam13 = cv2.VideoCapture(\"thesis_data/christian/13.mp4\")\n",
        "cam14 = cv2.VideoCapture(\"thesis_data/christian/14.mp4\")\n",
        "cam15 = cv2.VideoCapture(\"thesis_data/christian/15.mp4\")\n",
        "\n",
        "cam16 = [cam1, cam2, cam3, cam4,cam5, cam6, cam7, cam8,cam9, cam10, cam11, cam12,cam13, cam14, cam15]\n",
        "\n",
        "# Extracting basketball images form the basketball video\n",
        "  \n",
        "try: \n",
        "      \n",
        "    # creating a folder named basketball inside video_dataset \n",
        "    if os.path.exists('thesis_data'): \n",
        "        os.makedirs('thesis_data/christian') \n",
        "  # if not created then raise error \n",
        "except OSError: \n",
        "    print ('Error: Creating directory of data') \n",
        "  # frame \n",
        "currentframe = 0\n",
        "\n",
        "for cam in cam16:\n",
        "    \n",
        "    \n",
        "  \n",
        "    while(True):\n",
        "        ret,frame = cam.read()\n",
        "        if ret:\n",
        "    \n",
        "        # if video is still left continue creating images \n",
        "            name = 'thesis_data/christian/christian' + str(currentframe) + '.jpg'\n",
        "            print('Creating...' + name) \n",
        "  \n",
        "          # writing the extracted images \n",
        "            cv2.imwrite(name, frame) \n",
        "  \n",
        "        # increasing counter so that it will \n",
        "        # show how many frames are created \n",
        "            currentframe += 1\n",
        "        else: \n",
        "            break\n",
        "  # Release all space and windows once done \n",
        "cam.release() \n",
        "cv2.destroyAllWindows()\n",
        "\n",
        "\n",
        "\n",
        "# Read the video of basket from specified path \n",
        "cam1 = cv2.VideoCapture(\"thesis_data/muslim/m1.mp4\")\n",
        "cam2 = cv2.VideoCapture(\"thesis_data/muslim/m2.mp4\")\n",
        "cam3 = cv2.VideoCapture(\"thesis_data/muslim/m3.mp4\")\n",
        "cam4 = cv2.VideoCapture(\"thesis_data/muslim/m4.mp4\")\n",
        "cam5 = cv2.VideoCapture(\"thesis_data/muslim/m5.mp4\")\n",
        "cam6 = cv2.VideoCapture(\"thesis_data/muslim/m6.mp4\")\n",
        "cam7 = cv2.VideoCapture(\"thesis_data/muslim/m7.mp4\")\n",
        "cam8 = cv2.VideoCapture(\"thesis_data/muslim/m8.mp4\")\n",
        "cam9 = cv2.VideoCapture(\"thesis_data/muslim/m9.mp4\")\n",
        "cam10 = cv2.VideoCapture(\"thesis_data/muslim/m10.mp4\")\n",
        "cam11 = cv2.VideoCapture(\"thesis_data/muslim/m11.mp4\")\n",
        "cam12 = cv2.VideoCapture(\"thesis_data/muslim/m12.mp4\")\n",
        "\n",
        "cam13 = cv2.VideoCapture(\"thesis_data/muslim/m13.mp4\")\n",
        "cam14 = cv2.VideoCapture(\"thesis_data/muslim/m14.mp4\")\n",
        "cam15 = cv2.VideoCapture(\"thesis_data/muslim/m15.mp4\")\n",
        "\n",
        "cam16 = [cam1, cam2, cam3, cam4,cam5, cam6, cam7, cam8,cam9, cam10, cam11, cam12,cam13, cam14, cam15]\n",
        "\n",
        "# Extracting basketball images form the basketball video\n",
        "  \n",
        "try: \n",
        "      \n",
        "    # creating a folder named basketball inside video_dataset \n",
        "    if os.path.exists('thesis_data'): \n",
        "        os.makedirs('thesis_data/muslim') \n",
        "  # if not created then raise error \n",
        "except OSError: \n",
        "    print ('Error: Creating directory of data') \n",
        "  # frame \n",
        "currentframe = 0\n",
        "\n",
        "for cam in cam16:\n",
        "    \n",
        "    \n",
        "  \n",
        "    while(True):\n",
        "        ret,frame = cam.read()\n",
        "        if ret:\n",
        "    \n",
        "        # if video is still left continue creating images \n",
        "            name = 'thesis_data/muslim/muslim' + str(currentframe) + '.jpg'\n",
        "            print('Creating...' + name) \n",
        "  \n",
        "          # writing the extracted images \n",
        "            cv2.imwrite(name, frame) \n",
        "  \n",
        "        # increasing counter so that it will \n",
        "        # show how many frames are created \n",
        "            currentframe += 1\n",
        "        else: \n",
        "            break\n",
        "  # Release all space and windows once done \n",
        "cam.release() \n",
        "cv2.destroyAllWindows()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C3YNFeowqRM0"
      },
      "source": [
        "Christian_dir = os.listdir('/content/drive/My Drive/data/Christian_Praying')\n",
        "Muslim_dir = os.listdir('/content/drive/My Drive/data/Muslim_Praying')\n",
        "Buddho_dir = os.listdir('/content/drive/My Drive/data/Boddho_Praying')\n",
        "Hindu_dir = os.listdir('/content/drive/My Drive/data/Hindu_Praying')\n",
        "\n",
        "\n",
        "fp_Christian = '/content/drive/My Drive/data/Christian_Praying/'\n",
        "fp_Muslim= '/content/drive/My Drive/data/Muslim_Praying/'\n",
        "\n",
        "fp_Buddho = '/content/drive/My Drive/data/Boddho_Praying/'\n",
        "fp_Hindu = '/content/drive/My Drive/data/Hindu_Praying/'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6vLcILsIyjdY"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iEh5iMwOrJbj"
      },
      "source": [
        "images = []\n",
        "labels = []\n",
        "\n",
        "for i in Muslim_dir:\n",
        "    if i[-3] != 'n' and i[-3] != 'g':\n",
        "        image = cv2.imread(fp_Muslim+i)\n",
        "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "        image = cv2.resize(image, (224,224))\n",
        "        images.append(image)\n",
        "        labels.append('Muslim_Praying')\n",
        "        \n",
        "for i in Christian_dir:\n",
        "    image = cv2.imread(fp_Christian+i)\n",
        "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "    image = cv2.resize(image, (224,224))\n",
        "    images.append(image)\n",
        "    labels.append('Christian_Praying')\n",
        "\n",
        "for i in Buddho_dir:\n",
        "    image = cv2.imread(fp_Buddho+i)\n",
        "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "    image = cv2.resize(image, (224,224))\n",
        "    images.append(image)\n",
        "    labels.append('Boddho_Praying')\n",
        "\n",
        "for i in Hindu_dir:\n",
        "    image = cv2.imread(fp_Hindu+i)\n",
        "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "    image = cv2.resize(image, (224,224))\n",
        "    images.append(image)\n",
        "    labels.append('Hindu_Praying')\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lWT17TpL1BPQ"
      },
      "source": [
        "import pickle\n",
        "\n",
        "with open('/content/drive/My Drive/data/Rawimages.txt', 'wb') as fh:\n",
        "   pickle.dump(images, fh)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ouT9tVXHjD2H"
      },
      "source": [
        "import pickle\n",
        "pickle_off = open(\"/content/drive/My Drive/data/Rawimages.txt\", 'rb')\n",
        "img = pickle.load(pickle_off)\n",
        "img"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WQvhvghq7MiH"
      },
      "source": [
        "images[0].shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FOicFgY-8Kej"
      },
      "source": [
        "plt.imshow(images[300])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QaQ04RcL-pIh"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "plt.imshow(mpimg.imread('/content/drive/My Drive/data/Muslim_Praying/image_25839.jpg'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eihm6btA-pLd"
      },
      "source": [
        "labels"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "viQIOQW_-zTV"
      },
      "source": [
        "images = np.array(images)\n",
        "labels = np.array(labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5-GOX0SbnQd4"
      },
      "source": [
        "import pickle\n",
        "\n",
        "with open('/content/drive/My Drive/data/images.txt', 'wb') as fh:\n",
        "   pickle.dump(images, fh)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "68nngRJa5mvU"
      },
      "source": [
        "import pickle\n",
        "pickle_off = open(\"/content/drive/My Drive/data/images.txt\", 'rb')\n",
        "images = pickle.load(pickle_off)\n",
        "images"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SZqiH4PZ-6WB"
      },
      "source": [
        "images.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UmpuqgwK-8Sp"
      },
      "source": [
        "labels"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SuQb9mnx--4E"
      },
      "source": [
        "plt.imshow(images[100])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a5QSh2fL_F3i"
      },
      "source": [
        "lb = LabelBinarizer()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "asgzVhhY_QbE"
      },
      "source": [
        "labels = lb.fit_transform(labels)\n",
        "labels"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Tezq6JjC2dY"
      },
      "source": [
        "import pickle\n",
        "\n",
        "with open('/content/drive/My Drive/data/labels.txt', 'wb') as th:\n",
        "   pickle.dump(labels, th)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ld6u4WbX6AdV"
      },
      "source": [
        "import pickle\n",
        "pickle_off = open(\"/content/drive/My Drive/data/labels.txt\", 'rb')\n",
        "labels = pickle.load(pickle_off)\n",
        "labels"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ycMt8R4m_eOR"
      },
      "source": [
        "(trainX,testX,trainY,testY) = train_test_split(images,labels,test_size=0.3,stratify=labels,random_state=42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ntSnGCRW_uyu"
      },
      "source": [
        "print(trainX.shape)\n",
        "print(type(trainX))\n",
        "print(trainY.shape)\n",
        "print(type(trainY))\n",
        "print(testX.shape)\n",
        "print(type(testX))\n",
        "print(testY.shape)\n",
        "print(type(testY))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ukLoy1ai_5jH"
      },
      "source": [
        "testY"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WtfZL4LjAJvI"
      },
      "source": [
        "trainAug = ImageDataGenerator(\n",
        "\trotation_range=30,\n",
        "\tzoom_range=0.15,\n",
        "\twidth_shift_range=0.2,\n",
        "\theight_shift_range=0.2,\n",
        "\tshear_range=0.15,\n",
        "\thorizontal_flip=True,\n",
        "\tfill_mode=\"nearest\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ykvIJ7XtAQDB"
      },
      "source": [
        "valAug = ImageDataGenerator()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RmQdrMpbZzxq"
      },
      "source": [
        "mean = np.array([123.68, 116.779, 103.939], dtype=\"float32\")\n",
        "trainAug.mean = mean\n",
        "valAug.mean = mean"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kRRyWKLsATGH"
      },
      "source": [
        "baseModel = ResNet50(weights = 'imagenet',include_top=False,input_tensor=Input(shape=(224, 224, 3)))\n",
        "\n",
        "headModel = baseModel.output\n",
        "headModel = AveragePooling2D(pool_size=(7, 7))(headModel)\n",
        "headModel = Flatten(name=\"flatten\")(headModel)\n",
        "headModel = Dense(512, activation=\"relu\")(headModel)\n",
        "headModel = Dropout(0.5)(headModel)\n",
        "headModel = Dense(4, activation=\"softmax\")(headModel)\n",
        "\n",
        "\n",
        "model = Model(inputs=baseModel.input, outputs=headModel)\n",
        "\n",
        "for layer in baseModel.layers:\n",
        "\tlayer.trainable = False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wNoYbCszAgkH"
      },
      "source": [
        "\n",
        "BS = 32\n",
        "EPOCHS =5\n",
        "opt = Adam(lr=0.001)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CfaZkB9IAy-b"
      },
      "source": [
        "model.compile(optimizer = opt, loss = 'categorical_crossentropy', metrics = ['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q-RPfE5bA0T8"
      },
      "source": [
        "H = model.fit_generator(\n",
        "\ttrainAug.flow(trainX, trainY, batch_size=BS),\n",
        "\tsteps_per_epoch=len(trainX) // BS,\n",
        "\tvalidation_data=valAug.flow(testX, testY),\n",
        "\tvalidation_steps=len(testX) // BS,\n",
        "\tepochs=EPOCHS)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oulae8NmeY-2"
      },
      "source": [
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import itertools  \n",
        "\n",
        "print('Confusion Matrix')\n",
        "cm = confusion_matrix(testY.argmax(axis=1),predictions.argmax(axis=1))\n",
        "cm\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9DGLkjdEyyg1"
      },
      "source": [
        "#evaluate the network\n",
        "predictions=model.predict(x=testX.astype(\"float32\"),batch_size=32)\n",
        "print(\"Classification report\",classification_report(testY.argmax(axis=1),predictions.argmax(axis=1)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o71ZB8oHcVi1"
      },
      "source": [
        "\n",
        "plt.plot(H.history['accuracy'])\n",
        "plt.plot(H.history['val_accuracy'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'validation'], loc='upper left')\n",
        "plt.style.use(\"seaborn-darkgrid\")\n",
        "plt.title(\"Optimizer = Adam\")\n",
        "plt.show()\n",
        "# \"Loss\"\n",
        "plt.plot(H.history['loss'])\n",
        "plt.plot(H.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'validation'], loc='upper left')\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SJPlnrovA7YD"
      },
      "source": [
        "N = EPOCHS\n",
        "plt.style.use(\"seaborn-darkgrid\")\n",
        "plt.figure(figsize=(6,6))\n",
        "plt.plot(np.arange(0, N), H.history[\"loss\"], label=\"train_loss\")\n",
        "plt.plot(np.arange(0, N), H.history[\"val_loss\"], label=\"val_loss\")\n",
        "plt.plot(np.arange(0, N), H.history[\"accuracy\"], label=\"train_acc\")\n",
        "plt.plot(np.arange(0, N), H.history[\"val_accuracy\"], label=\"val_acc\")\n",
        "plt.title(\"Training Loss and Accuracy on Dataset\")\n",
        "plt.xlabel(\"Epoch \")\n",
        "plt.ylabel(\"Loss/Accuracy\")\n",
        "plt.legend(loc=\"lower left\")\n",
        "plt.title(\"Optimizer = Nadam\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2JyE7R1axB5Z"
      },
      "source": [
        "print(plt.style.available)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UtBBI4HMZkK8"
      },
      "source": [
        "\n",
        "from keras.models import load_model\n",
        "from collections import deque"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-RpxbV7Jexv3"
      },
      "source": [
        "model.save('/content/drive/My Drive/data/SGDreligionepochs50.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vriL-Ed1cVjd"
      },
      "source": [
        "model=load_model('/content/drive/My Drive/data/4religionepochs5.model')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eycEx62-e4LX"
      },
      "source": [
        "SIZE=128"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QoSH7towe_XJ"
      },
      "source": [
        "mean = np.array([123.68, 116.779, 103.939][::1], dtype=\"float32\")\n",
        "Q = deque(maxlen=SIZE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Tv_OndAgp4s"
      },
      "source": [
        "vs = cv2.VideoCapture('/content/drive/My Drive/version3.mp4')\n",
        "writer = None\n",
        "(W, H) = (None, None)\n",
        "\n",
        "# loop over frames from the video file stream\n",
        "while True:\n",
        "\t# read the next frame from the file\n",
        "\t(grabbed, frame) = vs.read()\n",
        "\n",
        "\t# if the frame was not grabbed, then we have reached the end\n",
        "\t# of the stream\n",
        "\tif not grabbed:\n",
        "\t\tbreak\n",
        "\n",
        "\t# if the frame dimensions are empty, grab them\n",
        "\tif W is None or H is None:\n",
        "\t\t(H, W) = frame.shape[:2]\n",
        "\n",
        "\t# clone the output frame, then convert it from BGR to RGB\n",
        "\t# ordering, resize the frame to a fixed 224x224, and then\n",
        "\t# perform mean subtraction\n",
        "\toutput = frame.copy()\n",
        "\tframe = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
        "\tframe = cv2.resize(frame, (224, 224)).astype(\"float32\")\n",
        "\tframe -= mean\n",
        "\n",
        "\t# make predictions on the frame and then update the predictions\n",
        "\t# queue\n",
        "\tpreds = model.predict(np.expand_dims(frame, axis=0))[0]\n",
        "\tQ.append(preds)\n",
        "\n",
        "\t# perform prediction averaging over the current history of\n",
        "\t# previous predictions\n",
        "\tresults = np.array(Q).mean(axis=0)\n",
        "\ti = np.argmax(results)\n",
        "\tlabel = labels\n",
        "\n",
        "\t# draw the activity on the output frame\n",
        "\ttext = \"activity: {}\".format(label)\n",
        "\tcv2.putText(output, text, (35, 50), cv2.FONT_HERSHEY_SIMPLEX,\n",
        "\t\t1.25, (0, 255, 0), 5)\n",
        "\n",
        "\t# check if the video writer is None\n",
        "\tif writer is None:\n",
        "\t\t# initialize our video writer\n",
        "\t\tfourcc = cv2.VideoWriter_fourcc(*\"MJPG\")\n",
        "\t\twriter = cv2.VideoWriter('/content/drive/My Drive/data/output_6.avi', fourcc, 30,(W, H), True)\n",
        "\n",
        "\t# write the output frame to disk\n",
        "\twriter.write(output)\n",
        "\n",
        "\t# show the output image\n",
        "\n",
        "\t# if the `q` key was pressed, break from the loop\n",
        "\t\n",
        "\n",
        "# release the file pointers\n",
        "print(\"[INFO] cleaning up...\")\n",
        "writer.release()\n",
        "vs.release()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QImymxAEiF4r"
      },
      "source": [
        "from keras.utils.vis_utils import plot_model\n",
        "plot_model(model, to_file='model_plot.png', show_shapes=True, show_layer_names=True)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eODRIgsfx5Ye"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qd5qZJI7x_zp"
      },
      "source": [
        "# Final evaluation of the model\n",
        "scores = model.evaluate(testX, testY, verbose=0)\n",
        "print (\"Error: \", 100-scores[1]*100)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P9zygwtLzg7T"
      },
      "source": [
        "Y_pred = model.predict(testX,verbose=2)\n",
        "y_pred = np.argmax(Y_pred,axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vQ7cJsNOzydA"
      },
      "source": [
        "for ix in range(4):\n",
        "    print (ix, confusion_matrix(np.argmax(testY,axis=1), y_pred)[ix].sum())\n",
        "print (confusion_matrix(np.argmax(testY,axis=1), y_pred))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BbbxNgop5aXT"
      },
      "source": [
        "model=load_model('religion.model')\n",
        "history2 = model.evaluate_generator(testX)\n",
        "# history2 = model.evaluate(test_generator) = model.evaluate_generator(test_generator)\n",
        "# history2 = model.evaluate(test_generator)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bA2Hqdsh1vjA"
      },
      "source": [
        " \n",
        "# predict probabilities for test set\n",
        "yhat_probs = model.predict(testX, verbose=0)\n",
        "# predict crisp classes for test set\n",
        "yhat_classes = model.predict_classes(testX, verbose=0)\n",
        "# reduce to 1d array\n",
        "yhat_probs = yhat_probs[:, 0]\n",
        "yhat_classes = yhat_classes[:, 0]\n",
        " \n",
        "# accuracy: (tp + tn) / (p + n)\n",
        "accuracy = accuracy_score(testY, yhat_classes)\n",
        "print('Accuracy: %f' % accuracy)\n",
        "# precision tp / (tp + fp)\n",
        "precision = precision_score(testY, yhat_classes)\n",
        "print('Precision: %f' % precision)\n",
        "# recall: tp / (tp + fn)\n",
        "recall = recall_score(testY, yhat_classes)\n",
        "print('Recall: %f' % recall)\n",
        "# f1: 2 tp / (2 tp + fp + fn)\n",
        "f1 = f1_score(testY, yhat_classes)\n",
        "print('F1 score: %f' % f1)\n",
        " \n",
        "# kappa\n",
        "kappa = cohen_kappa_score(testY, yhat_classes)\n",
        "print('Cohens kappa: %f' % kappa)\n",
        "# ROC AUC\n",
        "auc = roc_auc_score(testY, yhat_probs)\n",
        "print('ROC AUC: %f' % auc)\n",
        "# confusion matrix\n",
        "matrix = confusion_matrix(testY, yhat_classes)\n",
        "print(matrix)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sbKOSX4c6vgQ"
      },
      "source": [
        "\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "76w_8TuzgQxA"
      },
      "source": [
        "\n",
        "# study of sgd with adaptive learning rates in the blobs problem\n",
        "from sklearn.datasets import make_blobs\n",
        "from keras.layers import Dense\n",
        "from keras.models import Sequential\n",
        "from keras.optimizers import SGD\n",
        "from keras.utils import to_categorical\n",
        "from keras.callbacks import Callback\n",
        "from keras import backend\n",
        "from matplotlib import pyplot\n",
        " \n",
        "# fit a model and plot learning curve\n",
        "def fit_model(trainX, trainy, testX, testy, optimizer):\n",
        "\tBS = 32\n",
        "\tEPOCHS=1\n",
        " \n",
        "\t# compile model\n",
        "\tmodel.compile(optimizer = optimizer, loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
        "\tmodel.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
        "\t# fit model\n",
        "\thistory= model.fit_generator(\n",
        "\ttrainAug.flow(trainX, trainY, batch_size=BS),\n",
        "\tsteps_per_epoch=len(trainX) // BS,\n",
        "\tvalidation_data=valAug.flow(testX, testY),\n",
        "\tvalidation_steps=len(testX) // BS,\n",
        "\tepochs=EPOCHS)\n",
        "\t# plot learning curves\n",
        "\tpyplot.plot(history.history['accuracy'], label='train')\n",
        "\tpyplot.plot(history.history['val_accuracy'], label='test')\n",
        "\tpyplot.title('opt='+optimizer, pad=-200)\n",
        "  \n",
        "# create learning curves for different optimizers\n",
        "opt = SGD(lr=1e-4, momentum=0.9, decay=1e-4 / args[\"epochs\"])\n",
        "rms= RMSprop(\n",
        "    learning_rate=0.001,\n",
        "    rho=0.9,\n",
        "    momentum=0.0,\n",
        "    epsilon=1e-07,\n",
        "    centered=False,\n",
        "    name=\"RMSprop\",\n",
        "    **kwargs\n",
        "momentums = [opt, rms]\n",
        "for i in range(len(momentums)):\n",
        "\t# determine the plot number\n",
        "\tplot_no = 220 + (i+1)\n",
        "\tpyplot.subplot(plot_no)\n",
        "\t# fit model and plot learning curves for an optimizer\n",
        "\tfit_model(trainX, trainY, testX, testY, momentums[i])\n",
        "# show learning curves\n",
        "pyplot.show()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}